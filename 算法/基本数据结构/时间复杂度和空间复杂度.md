# 时间复杂度
> 「 大O符号表示法 」，即 T(n) = O(f(n))

我们先来看个例子：
```java
for(i=1; i<=n; ++i)
{
   j = i;
   j++;
}
```

通过「 大O符号表示法 」，这段代码的时间复杂度为：**O(n)**，为什么呢?

在 大O符号表示法中，**时间复杂度的公式是： T(n) = O( f(n) )，其中f(n) 表示每行代码执行次数之和，而 O 表示正比例关系，这个公式的全称是：算法的渐进时间复杂度 。**

我们继续看上面的例子，假设每行代码的执行时间都是一样的，我们用 `1颗粒时间` 来表示，
那么这个例子的第一行耗时是`1个颗粒时间`，
第三行的执行时间是` n个颗粒时间`，
第四行的执行时间也是 `n个颗粒时间`（第二行和第五行是符号，暂时忽略），
那么总时间就是`1颗粒时间 + n颗粒时间 + n颗粒时间` ，即 `(1+2n)个颗粒时间`，即：`T(n) =  (1+2n)*颗粒时间`，

从这个结果可以看出，**这个算法的耗时是随着n的变化而变化，因此，我们可以简化的将这个算法的时间复杂度表示为：T(n) =  O(n)**

为什么可以这么去简化呢，**因为大O符号表示法并不是用于来真实代表算法的执行时间的，它是用来表示代码执行时间的增长变化趋势的**。

所以上面的例子中，如果n无限大的时候，T(n) =  time(1+2n)中的常量1就没有意义了，倍数2也意义不大。因此直接简化为T(n) =  O(n) 就可以了。

常见的时间复杂度量级有：
* 常数阶O(1)

* 对数阶O(logN)

* 线性阶O(n)

* 线性对数阶O(nlogN)

* 平方阶O(n²)

* 立方阶O(n³)

* K次方阶O(n^k)

* 指数阶(2^n)

上面从上至下依次的时间复杂度越来越大，执行的效率越来越低。

## 1. 常数阶O(1)

无论代码执行了多少行，只要是没有循环等复杂结构，那这个代码的时间复杂度就都是O(1)，如：
```java
int i = 1;
int j = 2;
++i;
j++;
int m = i + j;
```
上述代码在执行的时候，它消耗的时候并不随着某个变量的增长而增长，那么无论这类代码有多长，即使有几万几十万行，都可以用O(1)来表示它的时间复杂度。
## 2. 线性阶O(n)
```java
for(i=1; i<=n; ++i)
{
   j = i;
   j++;
}
```

这段代码，for循环里面的代码会执行n遍，因此它消耗的时间是随着n的变化而变化的，

所以这类代码都可以用O(n)来表示它的时间复杂度。

## 3. 对数阶O(logN)
```java
int i = 1;
while(i<n)
{
    i = i * 2;
}
```

从上面代码可以看到，在while循环里面，每次都将 i 乘以 2，乘完之后，i 距离 n 就越来越近了。

我们试着求解一下，假设循环x次之后，i 就大于 2 了，此时这个循环就退出了，

也就是说 2 的 x 次方等于 n，那么 x = log2^n也就是说当循环 log2^n 次以后，这个代码就结束了。

因此这个代码的时间复杂度为：O(logn)

## 4. 线性对数阶O(nlogN)

线性对数阶O(nlogN) 其实非常容易理解，将时间复杂度为O(logn)的代码循环N遍的话，那么它的时间复杂度就是` n * O(logN)`，也就是了O(nlogN)。
```java
for(m=1; m<n; m++)
{
    i = 1;
    while(i<n)
    {
        i = i * 2;
    }
}
```
## 5. 平方阶O(n²)

平方阶O(n²) 就更容易理解了，如果把 O(n) 的代码再嵌套循环一遍，它的时间复杂度就是 O(n²) 了。

```java
for(x=1; i<=n; x++)
{
   for(i=1; i<=n; i++)
    {
       j = i;
       j++;
    }
}
```

这段代码其实就是嵌套了2层n循环，它的时间复杂度就是` O(n*n)`，即 `  O(n²)`

如果将其中一层循环的n改成m，即：
```java
for(x=1; i<=m; x++)
{
   for(i=1; i<=n; i++)
    {
       j = i;
       j++;
    }
}
```

那它的时间复杂度就变成了 `O(m*n)`

## 6. 立方阶O(n³)、K次方阶O(n^k)

参考上面的`O(n²)` 去理解就好了，`O(n³)`相当于三层n循环，其它的类似。

除此之外，其实还有 平均时间复杂度、均摊时间复杂度、最坏时间复杂度、最好时间复杂度 的分析方法，有点复杂，这里就不展开了。

# 空间复杂度


既然时间复杂度不是用来计算程序具体耗时的，那么空间复杂度也不是用来计算程序实际占用的空间的。

空间复杂度是对一个算法在运行过程中临时占用存储空间大小的一个量度，同样反映的是一个趋势，我们用 S(n) 来定义。

空间复杂度比较常用的有：O(1)、O(n)、O(n²)，我们下面来看看：

## 1. 空间复杂度 O(1)

如果算法执行所需要的临时空间不随着某个变量n的大小而变化，即此算法空间复杂度为一个常量，可表示为 O(1)

举例：
```java
int i = 1;
int j = 2;
++i;
j++;
int m = i + j;
```

代码中的 i、j、m 所分配的空间都不随着处理数据量变化，因此它的空间复杂度 S(n) = O(1)

### 2. 空间复杂度 O(n)

我们先看一个代码：
```java
int[] m = new int[n]
for(i=1; i<=n; ++i)
{
   j = i;
   j++;
}
```

这段代码中，第一行new了一个数组出来，这个数据占用的大小为n，这段代码的2-6行，虽然有循环，但没有再分配新的空间。

因此，这段代码的空间复杂度主要看第一行即可，即 S(n) = O(n)

